{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                              tweet  sentiment\n0  31963   studiolife aislife requires passion dedicatio...          1\n1  31964   user white supremacists want everyone to see ...          1\n2  31965  safe ways to heal your acne altwaystoheal heal...          1\n3  31966  is the hp and the cursed child book up for res...          1\n4  31967   3rd bihday to my amazing hilarious nephew eli...          1\n          id                                              tweet  sentiment\n6525   38488  what up news talking about kimbo slice ð ð â u...          0\n10197  42160   user when they don t get you any food ð comed...          1\n3587   35550  hello there sunshine ð ð â ï sunshine missohio...          1\n548    32511  100 amazing health benefits of cucumbers healt...          1\n13158  45121   user i can t wait until the show premieres gr...          1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('/home/manpreet/PycharmProjects/mps/PYTHONML/extradirforfile/twitter/twitteridtweetsenti.csv')   #reading csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                              tweet  sentiment\n0  31963   studiolife aislife requires passion dedicatio...          1\n1  31964   user white supremacists want everyone to see ...          1\n2  31965  safe ways to heal your acne altwaystoheal heal...          1\n3  31966  is the hp and the cursed child book up for res...          1\n4  31967   3rd bihday to my amazing hilarious nephew eli...          1\n          id                                              tweet  sentiment\n6525   38488  what up news talking about kimbo slice ð ð â u...          0\n10197  42160   user when they don t get you any food ð comed...          1\n3587   35550  hello there sunshine ð ð â ï sunshine missohio...          1\n548    32511  100 amazing health benefits of cucumbers healt...          1\n13158  45121   user i can t wait until the show premieres gr...          1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.utils import shuffle\n",
    "print(df.head())\n",
    "df= shuffle(df)     #shuffling the values in df_new\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "len=df.__len__()\n",
    "X_train = df.loc[:len//2,'tweet'].values\n",
    "y_train = df.loc[:len//2,'sentiment'].values\n",
    "X_test = df.loc[len//2:,'tweet'].values\n",
    "y_test = df.loc[len//2:,'sentiment'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression   #for predection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV #hyper-path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hotel': 1, 'food': 0, 'service': 2}\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')    #initialising TfidfVectorizer   \n",
    "\n",
    "#this creates the matrix of tfids for each word in the input file\n",
    "\n",
    "#stop_words='english is used to ignore common english word like 'the' 'a' which does not have meaning\n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/34449127/sklearn-tfidf-transformer-how-to-get-tf-idf-values-of-given-words-in-documen\n",
    "\n",
    "#example\n",
    "\n",
    "testtfidf=TfidfVectorizer(stop_words='english')\n",
    "\n",
    "corpus = [\"hotel food\",\"hotel food service\"]\n",
    "testtfidf.fit_transform(corpus)\n",
    "print(testtfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'clf__C':[1.0,10.0,100.0]}\n",
    "X_train.ndim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ir_tfidf = Pipeline([('vect',tfidf),('clf',LogisticRegression())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_Ir_tfidf = GridSearchCV(Ir_tfidf,param_grid,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(memory=None,\n     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n  ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False))]),\n       fit_params=None, iid=True, n_jobs=1,\n       param_grid={'clf__C': [1.0, 10.0, 100.0]}, pre_dispatch='2*n_jobs',\n       refit=True, return_train_score='warn', scoring='accuracy',\n       verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_Ir_tfidf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__C': 100.0} \nCV Accuracy: 0.914\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter set: %s ' % gs_Ir_tfidf.best_params_)\n",
    "#best_params_\n",
    "#Parameter setting that gave the best results on the hold out data.\n",
    "\n",
    "\n",
    "\n",
    "print('CV Accuracy: %.3f' % gs_Ir_tfidf.best_score_)\n",
    "\n",
    "\n",
    "#best_score_\n",
    "#Mean cross-validated score of the best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9279298099018174"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_Ir_tfidf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
