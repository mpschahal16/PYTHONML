{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review  sentiment\n0      Richard Brooks' The Last Hunt was a film star ...          1\n1      Pat Conroy's autobiographical book \"The Water ...          1\n2      The Five Deadly Venoms is easily the most memo...          1\n3      An interesting concept turned into carnage...<...          0\n4      Its not Braveheart( thankfully),but it is fine...          1\n5      I saw this movie a few years back on the BBC i...          0\n6      This movie was so bad I couldn't sit through i...          0\n7      Maybe the greatest film ever about jazz.<br />...          1\n8      One of the last surviving horror screen greats...          0\n9      New York attorney plots to rid himself of his ...          0\n10     As a French, i found it very pleasant to be ab...          1\n11     I can't believe I even tried to watch this fil...          0\n12     I saw this movie once in or close to its relea...          1\n13     I've waited a long time to see DR TARR'S TORTU...          0\n14     As a film buff, I obviously had read all the e...          1\n15     I just found the IMDb and searched this film a...          1\n16     Despite a decent first season this series neve...          0\n17     You do realize that you've been watching the E...          0\n18     I think the problem with this show not getting...          1\n19     When I played the first Soul Calibur on dreamc...          1\n20     ...I saw this on cable back in the late 1980's...          1\n21     This TVM seems to have polarised opinions amon...          0\n22     This is a great film Classic from the 40's and...          1\n23     Isn't it strange how crap-movies always tend t...          0\n24     Contrary to another reviewer, I think that thi...          0\n25     A May day 1938 when happen a huge rally celebr...          1\n26     I had watched as much of the series as I could...          1\n27     - A newlywed couple move into the home of the ...          0\n28     I have never read Sarah Water's book. Although...          1\n29     I can just picture how this movie came to be:<...          0\n...                                                  ...        ...\n49970  Besides all of the technical mistakes ....<br ...          0\n49971  Why is Guy working for Buddy? Probably because...          0\n49972  Too bad, I really like Kristen Cloke and Gary ...          0\n49973  I don't usually comment on films since I am in...          1\n49974  The war in the East,as the Germans referred to...          0\n49975  The only thing that prevented this flick from ...          0\n49976  To get in touch with the beauty of this film p...          1\n49977  It was awful plain and simple. What was their ...          0\n49978  Well, I'm an Italian horror big fan and I love...          1\n49979  This film is a massive Yawn proving that Ameri...          0\n49980  The eighties produced a lot of gory little hor...          1\n49981  Thank goodness not all Dutch people are that r...          1\n49982  The \"gangster\" genre is now a worn subject one...          1\n49983  I'm a great admirer of Lon Chaney, but the scr...          0\n49984  The action in this movie beats Sunny bhai in G...          0\n49985  very disappointing and incoherent - every now ...          0\n49986  I saw this movie with low expectations and was...          0\n49987  Technically abominable (with audible \"pops\" be...          0\n49988  Maybe I'm reading into this too much, but I wo...          1\n49989  As I type these comments I'm watching a DVD of...          1\n49990  I have a 5 minute rule (sometimes I'll leave l...          0\n49991  Yuck! And again I say...YUCK! The original ver...          0\n49992  Years ago I saw The Godfather and it made a la...          0\n49993  As a Bruce Campbell fan for nearly two decades...          0\n49994  Wirey's journey through the final days of bach...          1\n49995  Ex-reporter Jacob Asch (Eric Roberts) is hired...          1\n49996  UNCONDITIONAL LOVE is surprisingly entertainin...          1\n49997  Okay, enough. Every time I think I've seen a f...          0\n49998  Cute idea... salesgirl Linda Smith (Yolande Do...          1\n49999  A patient escapes from a mental hospital, kill...          0\n\n[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  #importing pandas\n",
    "import numpy as np    #importing numpy\n",
    "df_new= pd.read_csv('/home/manpreet/mps/cc/aclImdb_v1/aclImdb/movie_reviews.csv')   #reading csv\n",
    "df_new.head()    #print some value from top of df_new\n",
    "print(df_new)\n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25000\n0    25000\nName: sentiment, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_new.sentiment.value_counts()  #this counts the occurance of allsentiments and print the correspondence value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n0  Richard Brooks' The Last Hunt was a film star ...          1\n1  Pat Conroy's autobiographical book \"The Water ...          1\n2  The Five Deadly Venoms is easily the most memo...          1\n3  An interesting concept turned into carnage...<...          0\n4  Its not Braveheart( thankfully),but it is fine...          1\n                                                  review  sentiment\n11235  \"The Aristocats\" is classic Disney at it's bes...          1\n7877   This is one of those movies that they did too ...          1\n41364  I only saw this movie once, and that was enoug...          0\n40445  As I said, sometimes low budget is good. You g...          0\n25345  Considering all the teen films like \"the Break...          1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.utils import shuffle\n",
    "print(df_new.head())\n",
    "df_new = shuffle(df_new)     #shuffling the values in df_new\n",
    "print(df_new.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re    ##importing regular expression\n",
    "def preprocessor(text):   #function to remove extra thing from the string for ex emoticons\n",
    "    \n",
    "    #we are using regular expression to determine emoticons and other extra things\n",
    "   text = re.sub('<[^>]*>','',text)     \n",
    "   emoticons = re.findall('[:;=](?:-)', text)\n",
    "   text = (re.sub('[\\W]+',' ',text.lower())+ ' '.join(emoticons).replace('-',''))\n",
    "   \n",
    "   return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test :'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(\"</a>This is# a ;test ::-)!</a>\")   #example what above function is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11235</th>\n",
       "      <td>the aristocats is classic disney at it s best...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7877</th>\n",
       "      <td>this is one of those movies that they did too ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41364</th>\n",
       "      <td>i only saw this movie once and that was enough...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40445</th>\n",
       "      <td>as i said sometimes low budget is good you get...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25345</th>\n",
       "      <td>considering all the teen films like the breakf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11235</th>\n",
       "      <td>the aristocats is classic disney at it s best...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7877</th>\n",
       "      <td>this is one of those movies that they did too ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41364</th>\n",
       "      <td>i only saw this movie once and that was enough...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40445</th>\n",
       "      <td>as i said sometimes low budget is good you get...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25345</th>\n",
       "      <td>considering all the teen films like the breakf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['review'] = df_new['review'].apply(preprocessor)   #applying above defined function to all the reviews and\n",
    "#then replacing those reviews\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the aristocats is classic disney at it s best...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is one of those movies that they did too ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i only saw this movie once and that was enough...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>as i said sometimes low budget is good you get...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>considering all the teen films like the breakf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the aristocats is classic disney at it s best...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is one of those movies that they did too ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i only saw this movie once and that was enough...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>as i said sometimes low budget is good you get...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>considering all the teen films like the breakf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.index  =range(50000)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_new.loc[:2500,'review'].values\n",
    "y_train = df_new.loc[:2500,'sentiment'].values\n",
    "X_test = df_new.loc[2500:,'review'].values\n",
    "y_test = df_new.loc[2500:,'sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23773 23727]\n\n\nEXample result\n\n[0 2 1 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# bincount creates the list of counts of index that occur in the list\n",
    "\n",
    "#for ex a=[1,2,1,3,4,5,5,5]\n",
    "#index are 0,1,2,3,4,5,6,7 respectively for 1,2,1,3,4,5,5,5\n",
    "\n",
    "#bincount will count the occurrence of index in self \n",
    "# ex below\n",
    "print(\"\\n\\nEXample result\\n\")\n",
    "a=np.array([1,2,1,3,4,5,5,5])\n",
    "print(np.bincount(a))\n",
    "\n",
    "#occurrence of INDEX is NO.OF TIME in array a\n",
    "#occurrence of 0 is 0 in array a\n",
    "#occurrence of 1 is 2 in array a\n",
    "#occurrence of 2 is 1 in array a\n",
    "#occurrence of 2 is 2 in array a\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n\n\nEXample result\n\n[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_test))\n",
    "\n",
    "#print all the unique values in array means no repeatation\n",
    "\n",
    "#example\n",
    "print(\"\\n\\nEXample result\\n\")\n",
    "a=np.array([1,2,1,3,4,5,5,5])\n",
    "print(np.unique(a))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression   #for predection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV #hyper-path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hotel': 1, 'food': 0, 'service': 2}\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')    #initialising TfidfVectorizer   \n",
    "\n",
    "#this creates the matrix of tfids for each word in the input file\n",
    "\n",
    "#stop_words='english is used to ignore common english word like 'the' 'a' which does not have meaning\n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/34449127/sklearn-tfidf-transformer-how-to-get-tf-idf-values-of-given-words-in-documen\n",
    "\n",
    "#example\n",
    "\n",
    "testtfidf=TfidfVectorizer(stop_words='english')\n",
    "\n",
    "corpus = [\"hotel food\",\"hotel food service\"]\n",
    "testtfidf.fit_transform(corpus)\n",
    "print(testtfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param_grid = {'clf__C':[1.0,10.0,100.0]}\n",
    "X_train.ndim   #print the Number of array dimensions.\n",
    "\n",
    "#here dimension means real world dimensions 1d 2d 3d or nd\n",
    "\n",
    "#example is given below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 1 2 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a1 = np.array(111)\n",
    "b1 = np.array([1,2])\n",
    "c1 = np.array([[1,2], [4,5]])\n",
    "d1 = np.array([[1,2,3,], [4,5,]])\n",
    "e1=np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "f1=np.array([[[0, 0, 0], [0, 0, 0], [0, 0, 0]],\n",
    " [[0, 0, 0], [0, 0, 0], [0, 0, 0]],\n",
    " [[0, 0, 0], [0, 0, 0], [0, 0, 0]]])   #this is a 3d array\n",
    "print(a1.ndim, b1.ndim, c1.ndim, d1.ndim, e1.ndim,f1.ndim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ir_tfidf = Pipeline([('vect',tfidf),('clf',LogisticRegression())])\n",
    "\n",
    "\n",
    "#applying multiple transform sequentially and then estimater\n",
    "\n",
    "\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "#https://stackoverflow.com/questions/33091376/python-what-is-exactly-sklearn-pipeline-pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gs_Ir_tfidf = GridSearchCV(Ir_tfidf,param_grid,scoring='accuracy')\n",
    "\n",
    "#Exhaustive search over specified parameter values for an estimator.\n",
    "\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(memory=None,\n     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n  ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False))]),\n       fit_params=None, iid=True, n_jobs=1,\n       param_grid={'clf__C': [1.0, 10.0, 100.0]}, pre_dispatch='2*n_jobs',\n       refit=True, return_train_score='warn', scoring='accuracy',\n       verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n       estimator=Pipeline(memory=None,\n     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n  ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False))]),\n       fit_params=None, iid=True, n_jobs=1,\n       param_grid={'clf__C': [1.0, 10.0, 1000.0]}, pre_dispatch='2*n_jobs',\n       refit=True, return_train_score='warn', scoring='accuracy',\n       verbose=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_Ir_tfidf.fit(X_train,y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n  ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter set: %s ' % gs_Ir_tfidf.best_params_)\n",
    "#best_params_\n",
    "#Parameter setting that gave the best results on the hold out data.\n",
    "\n",
    "\n",
    "\n",
    "print('CV Accuracy: %.3f' % gs_Ir_tfidf.best_score_)\n",
    "\n",
    "\n",
    "#best_score_\n",
    "#Mean cross-validated score of the best_estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n  ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print(gs_Ir_tfidf.best_estimator_)\n",
    "\n",
    "#Estimator that was chosen by the search, \n",
    "# i.e. estimator which gave highest score (or smallest loss if specified) on the left out data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8479368421052632"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4 3 0 4]\n [1 4 0 4 0]\n [0 3 1 4 1]\n [2 3 1 1 2]\n [1 2 0 0 0]\n [4 0 3 3 2]] \n\n[1 2 3 4 5 6] \n\n[[0 3 1 4 1]]\n[3]\n"
     ]
    }
   ],
   "source": [
    "nb = Pipeline([('vect', tfidf),('clf', MultinomialNB())])\n",
    "\n",
    "#The multinomial Naive Bayes classifier is suitable for classification with discrete features \n",
    "# (e.g., word counts for text classification). The multinomial distribution normally requires integer\n",
    "#  feature counts. However, in practice, fractional counts such as tf-idf may also work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4 3 0 4]\n [1 4 0 4 0]\n [0 3 1 4 1]\n [2 3 1 1 2]\n [1 2 0 0 0]\n [4 0 3 3 2]] \n\n[1 2 3 4 5 6] \n\n[[0 3 1 4 1]]\n[3]\n"
     ]
    }
   ],
   "source": [
    "##example of multinomial Naive Bayes\n",
    "Xx= np.random.randint(5, size=(6, 5))\n",
    "print(Xx,\"\\n\")\n",
    "\n",
    "yy= np.array([1, 2, 3, 4, 5, 6])\n",
    "print(yy,\"\\n\")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(Xx, yy)\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "print(Xx[2:3])\n",
    "print(clf.predict(Xx[2:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n  ...rue,\n        vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9768092762894842"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2501, 28276)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2501, 28276)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cv = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2501, 28276)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_data = cv.fit_transform(X_train)\n",
    "new_test = cv.transform(X_test)\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(new_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8403578947368421"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(new_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9768092762894842"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(new_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
